{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exercise6.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2, 5]\n",
      "[3, 5]\n",
      "[4, 5]\n",
      "[4, 4]\n",
      "[4, 5]\n",
      "[5, 5]\n",
      "[6, 5]\n",
      "[7, 5]\n",
      "[8, 5]\n",
      "[9, 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tnrange\n",
    "\n",
    "def ep_greedy(ep, action_value, n_action):\n",
    "    greedy_action = action_value.argmax()\n",
    "    if np.random.uniform(low=0, high=1) > n_action * ep:\n",
    "        action = greedy_action\n",
    "    else:\n",
    "        action = np.random.randint(low=0, high=n_action)\n",
    "    return action\n",
    "\n",
    "class windy_grid_world(object):\n",
    "    \n",
    "    def __init__(self, n_row, n_column, spc_area, start_point, goal_point):\n",
    "        self.q_value = np.zeros((n_row, n_column, 4))\n",
    "        assert len(spc_area) == 4\n",
    "        self.n_row = n_row\n",
    "        self.n_column = n_column\n",
    "        self.spc_area = spc_area\n",
    "        self.start_point = start_point\n",
    "        self.goal_point = goal_point\n",
    "        self.ep = 0.05\n",
    "        self.alpha = 0.5\n",
    "        self.gamma = 1\n",
    "        self.action = dict()\n",
    "        self.action['2'] = [0, 1]\n",
    "        self.action['3'] = [0, -1]\n",
    "        self.action['0'] = [-1, 0]\n",
    "        self.action['1'] = [1, 0]\n",
    "    \n",
    "    def find_q_value(self, state, action):\n",
    "        q_value = self.q_value[state[0], state[1], action]\n",
    "        return q_value\n",
    "    \n",
    "    def one_episode(self, printFlag=False):\n",
    "        init_state = self.start_point\n",
    "        next_state = [0, 0]\n",
    "        init_q_avilable_value = self.q_value[init_state[0], init_state[1], :]\n",
    "        if init_q_avilable_value.argmax() == init_q_avilable_value.argmin():\n",
    "            action = int(np.random.randint(low=0, high=4))\n",
    "        else:\n",
    "            action = int(ep_greedy(ep=self.ep, action_value=init_q_avilable_value, n_action = 4))\n",
    "        actionstr = str(action)\n",
    "        change = self.action[actionstr]\n",
    "        next_state_temp = [init_state[0] + change[0], init_state[1] + change[1]]\n",
    "        next_state[0] = max(next_state_temp[0], 0)\n",
    "        next_state[0] = min(next_state[0], self.n_row-1)\n",
    "        next_state[1] = max(next_state_temp[1], 0)\n",
    "        next_state[1] = min(next_state[1], self.n_column-1)\n",
    "        last_state = init_state[:]\n",
    "        state = next_state[:]\n",
    "        last_action = action\n",
    "        while state != self.goal_point:\n",
    "            q_avilable_value = self.q_value[state[0], state[1], :]\n",
    "            if q_avilable_value.argmax() == q_avilable_value.argmin():\n",
    "                action = int(np.random.randint(low=0, high=4))\n",
    "            else:\n",
    "                action = int(ep_greedy(ep=self.ep, action_value=q_avilable_value, n_action = 4))\n",
    "            actionstr = str(action)\n",
    "            change = self.action[actionstr]\n",
    "            next_state_temp = [state[0] + change[0], state[1] + change[1]]\n",
    "            next_state[0] = max(next_state_temp[0], 0)\n",
    "            next_state[0] = min(next_state[0], self.n_row-1)\n",
    "            next_state[1] = max(next_state_temp[1], 0)\n",
    "            next_state[1] = min(next_state[1], self.n_column-1)\n",
    "            reward = -1\n",
    "            q_value_change = self.alpha * (reward + self.gamma * self.q_value[state[0], state[1], action] - self.q_value[last_state[0], last_state[1], last_action])\n",
    "            self.q_value[last_state[0], last_state[1], last_action] = self.q_value[last_state[0], last_state[1], last_action] + q_value_change\n",
    "            last_state = state[:]\n",
    "            state = next_state[:]\n",
    "            last_action = action\n",
    "            if printFlag == True:\n",
    "                print state\n",
    "\n",
    "        \n",
    "windy_grid = windy_grid_world(10, 10, [2, 3, 2, 3], [0, 5], [9, 5])\n",
    "for i in tnrange(1000):\n",
    "    windy_grid.one_episode()\n",
    "windy_grid.one_episode(printFlag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[5, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[6, 5]\n",
      "[7, 6]\n",
      "[8, 7]\n",
      "[9, 7]\n",
      "[9, 7]\n",
      "[9, 7]\n",
      "[9, 8]\n",
      "[9, 9]\n",
      "[8, 9]\n",
      "[7, 9]\n",
      "[6, 9]\n",
      "[5, 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tnrange\n",
    "\n",
    "def ep_greedy(ep, action_value, n_action):\n",
    "    greedy_action = action_value.argmax()\n",
    "    if np.random.uniform(low=0, high=1) > n_action * ep:\n",
    "        action = greedy_action\n",
    "    else:\n",
    "        action = np.random.randint(low=0, high=n_action)\n",
    "    return action\n",
    "\n",
    "def is_in_spc_area(spc_area, state):\n",
    "    flag = 1\n",
    "    if spc_area[0] <= state[0]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    if spc_area[1] >= state[0]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    if spc_area[2] <= state[1]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    if spc_area[3] >= state[1]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    return flag\n",
    "\n",
    "class windy_grid_world(object):\n",
    "    \n",
    "    def __init__(self, n_row, n_column, spc_area, start_point, goal_point):\n",
    "        self.q_value = np.zeros((n_row, n_column, 4))\n",
    "        assert len(spc_area) == 4\n",
    "        self.n_row = n_row\n",
    "        self.n_column = n_column\n",
    "        self.spc_area = spc_area\n",
    "        self.start_point = start_point\n",
    "        self.goal_point = goal_point\n",
    "        self.ep = 0.05\n",
    "        self.alpha = 0.5\n",
    "        self.gamma = 1\n",
    "        self.action = dict()\n",
    "        self.action['2'] = [0, 1]\n",
    "        self.action['3'] = [0, -1]\n",
    "        self.action['0'] = [-1, 0]\n",
    "        self.action['1'] = [1, 0]\n",
    "    \n",
    "    def one_episode(self, printFlag=False):\n",
    "        init_state = self.start_point\n",
    "        next_state = [0, 0]\n",
    "        init_q_avilable_value = self.q_value[init_state[0], init_state[1], :]\n",
    "        if init_q_avilable_value.argmax() == init_q_avilable_value.argmin():\n",
    "            action = int(np.random.randint(low=0, high=4))\n",
    "        else:\n",
    "            action = int(ep_greedy(ep=self.ep, action_value=init_q_avilable_value, n_action = 4))\n",
    "        actionstr = str(action)\n",
    "        change = self.action[actionstr]\n",
    "        next_state_temp = [init_state[0] + change[0], init_state[1] + change[1]]\n",
    "        next_state[0] = max(next_state_temp[0], 0)\n",
    "        next_state[0] = min(next_state[0], self.n_row-1)\n",
    "        next_state[1] = max(next_state_temp[1], 0)\n",
    "        next_state[1] = min(next_state[1], self.n_column-1)\n",
    "        last_state = init_state[:]\n",
    "        state = next_state[:]\n",
    "        last_action = action\n",
    "        while state != self.goal_point:\n",
    "            q_avilable_value = self.q_value[state[0], state[1], :]\n",
    "            if q_avilable_value.argmax() == q_avilable_value.argmin():\n",
    "                action = int(np.random.randint(low=0, high=4))\n",
    "            else:\n",
    "                action = int(ep_greedy(ep=self.ep, action_value=q_avilable_value, n_action = 4))\n",
    "            actionstr = str(action)\n",
    "            change = self.action[actionstr]\n",
    "            next_state_temp = [state[0] + change[0] + is_in_spc_area(self.spc_area, state), state[1] + change[1]]\n",
    "            next_state[0] = max(next_state_temp[0], 0)\n",
    "            next_state[0] = min(next_state[0], self.n_row-1)\n",
    "            next_state[1] = max(next_state_temp[1], 0)\n",
    "            next_state[1] = min(next_state[1], self.n_column-1)\n",
    "            reward = -1\n",
    "            q_value_change = self.alpha * (reward + self.gamma * self.q_value[state[0], state[1], action] - self.q_value[last_state[0], last_state[1], last_action])\n",
    "            self.q_value[last_state[0], last_state[1], last_action] = self.q_value[last_state[0], last_state[1], last_action] + q_value_change\n",
    "            last_state = state[:]\n",
    "            state = next_state[:]\n",
    "            last_action = action\n",
    "            if printFlag == True:\n",
    "                print state\n",
    "\n",
    "        \n",
    "windy_grid = windy_grid_world(10, 10, [0, 9, 4, 7], [5, 0], [5, 9])\n",
    "for i in tnrange(1000):\n",
    "    windy_grid.one_episode()\n",
    "windy_grid.one_episode(printFlag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testing one episode:\n",
      "[6, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[5, 5]\n",
      "[5, 6]\n",
      "[6, 7]\n",
      "[6, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[6, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[5, 5]\n",
      "[5, 6]\n",
      "[6, 7]\n",
      "[6, 8]\n",
      "[5, 7]\n",
      "[5, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[6, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[5, 5]\n",
      "[5, 6]\n",
      "[6, 7]\n",
      "[6, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[6, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[5, 5]\n",
      "[5, 6]\n",
      "[6, 7]\n",
      "[6, 8]\n",
      "[7, 7]\n",
      "[7, 8]\n",
      "[6, 9]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[6, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[5, 5]\n",
      "[5, 6]\n",
      "[6, 7]\n",
      "[6, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[6, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[5, 5]\n",
      "[5, 6]\n",
      "[5, 7]\n",
      "[5, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[6, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[5, 5]\n",
      "[5, 6]\n",
      "[5, 7]\n",
      "[5, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[6, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[4, 3]\n",
      "[4, 4]\n",
      "[4, 5]\n",
      "[6, 6]\n",
      "[6, 7]\n",
      "[6, 8]\n",
      "[7, 8]\n",
      "[6, 9]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[6, 1]\n",
      "[7, 0]\n",
      "[7, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[5, 5]\n",
      "[5, 6]\n",
      "[5, 7]\n",
      "[5, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[6, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[5, 4]\n",
      "[5, 5]\n",
      "[5, 6]\n",
      "[5, 7]\n",
      "[5, 8]\n",
      "[5, 9]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tnrange\n",
    "\n",
    "def ep_greedy(ep, action_value, n_action):\n",
    "    greedy_action = action_value.argmax()\n",
    "    if np.random.uniform(low=0, high=1) > n_action * ep:\n",
    "        action = greedy_action\n",
    "    else:\n",
    "        action = np.random.randint(low=0, high=n_action)\n",
    "    return action\n",
    "\n",
    "def is_in_spc_area(spc_area, state):\n",
    "    flag = 1\n",
    "    if spc_area[0] <= state[0]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    if spc_area[1] >= state[0]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    if spc_area[2] <= state[1]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    if spc_area[3] >= state[1]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    return flag\n",
    "\n",
    "class windy_grid_world(object):\n",
    "    \n",
    "    def __init__(self, n_row, n_column, spc_area, start_point, goal_point):\n",
    "        self.q_value = np.zeros((n_row, n_column, 8))\n",
    "        assert len(spc_area) == 4\n",
    "        self.n_row = n_row\n",
    "        self.n_column = n_column\n",
    "        self.spc_area = spc_area\n",
    "        self.start_point = start_point\n",
    "        self.goal_point = goal_point\n",
    "        self.ep = 0.01\n",
    "        self.alpha = 0.5\n",
    "        self.gamma = 1\n",
    "        self.action = dict()\n",
    "        self.action['2'] = [0, 1]\n",
    "        self.action['3'] = [0, -1]\n",
    "        self.action['0'] = [-1, 0]\n",
    "        self.action['1'] = [1, 0]\n",
    "        self.action['4'] = [1, 1]\n",
    "        self.action['5'] = [1, -1]\n",
    "        self.action['6'] = [-1, 1]\n",
    "        self.action['7'] = [-1, -1]\n",
    "    \n",
    "    def one_episode(self, printFlag=False):\n",
    "        init_state = self.start_point\n",
    "        next_state = [0, 0]\n",
    "        init_q_avilable_value = self.q_value[init_state[0], init_state[1], :]\n",
    "        if init_q_avilable_value.argmax() == init_q_avilable_value.argmin():\n",
    "            action = int(np.random.randint(low=0, high=8))\n",
    "        else:\n",
    "            action = int(ep_greedy(ep=self.ep, action_value=init_q_avilable_value, n_action = 8))\n",
    "        actionstr = str(action)\n",
    "        change = self.action[actionstr]\n",
    "        next_state_temp = [init_state[0] + change[0], init_state[1] + change[1]]\n",
    "        next_state[0] = max(next_state_temp[0], 0)\n",
    "        next_state[0] = min(next_state[0], self.n_row-1)\n",
    "        next_state[1] = max(next_state_temp[1], 0)\n",
    "        next_state[1] = min(next_state[1], self.n_column-1)\n",
    "        last_state = init_state[:]\n",
    "        state = next_state[:]\n",
    "        last_action = action\n",
    "        if printFlag == True:\n",
    "            print state\n",
    "        while state != self.goal_point:\n",
    "            q_avilable_value = self.q_value[state[0], state[1], :]\n",
    "            if q_avilable_value.argmax() == q_avilable_value.argmin():\n",
    "                action = int(np.random.randint(low=0, high=8))\n",
    "            else:\n",
    "                action = int(ep_greedy(ep=self.ep, action_value=q_avilable_value, n_action = 8))\n",
    "            actionstr = str(action)\n",
    "            change = self.action[actionstr]\n",
    "            next_state_temp = [state[0] + change[0] + is_in_spc_area(self.spc_area, state), state[1] + change[1]]\n",
    "            next_state[0] = max(next_state_temp[0], 0)\n",
    "            next_state[0] = min(next_state[0], self.n_row-1)\n",
    "            next_state[1] = max(next_state_temp[1], 0)\n",
    "            next_state[1] = min(next_state[1], self.n_column-1)\n",
    "            reward = -1\n",
    "            q_value_change = self.alpha * (reward + self.gamma * self.q_value[state[0], state[1], action] - self.q_value[last_state[0], last_state[1], last_action])\n",
    "            self.q_value[last_state[0], last_state[1], last_action] = self.q_value[last_state[0], last_state[1], last_action] + q_value_change\n",
    "            last_state = state[:]\n",
    "            state = next_state[:]\n",
    "            last_action = action\n",
    "            if printFlag == True:\n",
    "                print state\n",
    "\n",
    "        \n",
    "windy_grid = windy_grid_world(10, 10, [0, 9, 4, 7], [5, 0], [5, 9])\n",
    "for i in tnrange(4000):\n",
    "    windy_grid.one_episode()\n",
    "for j in tnrange(10):\n",
    "    print 'testing one episode:'\n",
    "    windy_grid.one_episode(printFlag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "testing one episode:\n",
      "[4, 1]\n",
      "[3, 2]\n",
      "[2, 3]\n",
      "[3, 4]\n",
      "[2, 5]\n",
      "[4, 6]\n",
      "[3, 7]\n",
      "[5, 6]\n",
      "[5, 7]\n",
      "[5, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[4, 1]\n",
      "[3, 2]\n",
      "[2, 3]\n",
      "[3, 4]\n",
      "[4, 5]\n",
      "[6, 5]\n",
      "[8, 5]\n",
      "[8, 6]\n",
      "[8, 7]\n",
      "[6, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[4, 1]\n",
      "[3, 2]\n",
      "[2, 3]\n",
      "[3, 4]\n",
      "[2, 5]\n",
      "[1, 5]\n",
      "[2, 6]\n",
      "[4, 7]\n",
      "[3, 8]\n",
      "[4, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[4, 1]\n",
      "[3, 2]\n",
      "[2, 3]\n",
      "[3, 4]\n",
      "[3, 4]\n",
      "[3, 5]\n",
      "[3, 6]\n",
      "[5, 7]\n",
      "[5, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[4, 1]\n",
      "[3, 2]\n",
      "[2, 3]\n",
      "[3, 4]\n",
      "[4, 5]\n",
      "[5, 6]\n",
      "[6, 7]\n",
      "[5, 6]\n",
      "[4, 7]\n",
      "[4, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[4, 1]\n",
      "[3, 2]\n",
      "[2, 3]\n",
      "[3, 4]\n",
      "[3, 5]\n",
      "[4, 6]\n",
      "[2, 7]\n",
      "[3, 7]\n",
      "[5, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[4, 1]\n",
      "[3, 2]\n",
      "[4, 1]\n",
      "[3, 2]\n",
      "[4, 3]\n",
      "[4, 4]\n",
      "[3, 5]\n",
      "[2, 6]\n",
      "[2, 7]\n",
      "[4, 7]\n",
      "[4, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[4, 1]\n",
      "[5, 2]\n",
      "[4, 3]\n",
      "[4, 4]\n",
      "[4, 5]\n",
      "[6, 6]\n",
      "[6, 7]\n",
      "[5, 8]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[6, 0]\n",
      "[7, 1]\n",
      "[6, 2]\n",
      "[5, 3]\n",
      "[6, 4]\n",
      "[5, 5]\n",
      "[4, 6]\n",
      "[3, 7]\n",
      "[3, 8]\n",
      "[4, 8]\n",
      "[3, 8]\n",
      "[4, 9]\n",
      "[5, 9]\n",
      "testing one episode:\n",
      "[4, 1]\n",
      "[5, 2]\n",
      "[4, 3]\n",
      "[4, 4]\n",
      "[4, 4]\n",
      "[3, 5]\n",
      "[3, 6]\n",
      "[4, 7]\n",
      "[3, 8]\n",
      "[4, 9]\n",
      "[5, 9]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tnrange\n",
    "\n",
    "def ep_greedy(ep, action_value, n_action):\n",
    "    greedy_action = action_value.argmax()\n",
    "    if np.random.uniform(low=0, high=1) > n_action * ep:\n",
    "        action = greedy_action\n",
    "    else:\n",
    "        action = np.random.randint(low=0, high=n_action)\n",
    "    return action\n",
    "\n",
    "def is_in_spc_area(spc_area, state):\n",
    "    flag = np.random.randint(low=-1, high=2)\n",
    "    if spc_area[0] <= state[0]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    if spc_area[1] >= state[0]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    if spc_area[2] <= state[1]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    if spc_area[3] >= state[1]:\n",
    "        flag = flag * 1\n",
    "    else:\n",
    "        flag = flag * 0\n",
    "    return flag\n",
    "\n",
    "class windy_grid_world(object):\n",
    "    \n",
    "    def __init__(self, n_row, n_column, spc_area, start_point, goal_point):\n",
    "        self.q_value = np.zeros((n_row, n_column, 8))\n",
    "        assert len(spc_area) == 4\n",
    "        self.n_row = n_row\n",
    "        self.n_column = n_column\n",
    "        self.spc_area = spc_area\n",
    "        self.start_point = start_point\n",
    "        self.goal_point = goal_point\n",
    "        self.ep = 0.01\n",
    "        self.alpha = 0.5\n",
    "        self.gamma = 1\n",
    "        self.action = dict()\n",
    "        self.action['2'] = [0, 1]\n",
    "        self.action['3'] = [0, -1]\n",
    "        self.action['0'] = [-1, 0]\n",
    "        self.action['1'] = [1, 0]\n",
    "        self.action['4'] = [1, 1]\n",
    "        self.action['5'] = [1, -1]\n",
    "        self.action['6'] = [-1, 1]\n",
    "        self.action['7'] = [-1, -1]\n",
    "    \n",
    "    def one_episode(self, printFlag=False):\n",
    "        init_state = self.start_point\n",
    "        next_state = [0, 0]\n",
    "        init_q_avilable_value = self.q_value[init_state[0], init_state[1], :]\n",
    "        if init_q_avilable_value.argmax() == init_q_avilable_value.argmin():\n",
    "            action = int(np.random.randint(low=0, high=8))\n",
    "        else:\n",
    "            action = int(ep_greedy(ep=self.ep, action_value=init_q_avilable_value, n_action = 8))\n",
    "        actionstr = str(action)\n",
    "        change = self.action[actionstr]\n",
    "        next_state_temp = [init_state[0] + change[0], init_state[1] + change[1]]\n",
    "        next_state[0] = max(next_state_temp[0], 0)\n",
    "        next_state[0] = min(next_state[0], self.n_row-1)\n",
    "        next_state[1] = max(next_state_temp[1], 0)\n",
    "        next_state[1] = min(next_state[1], self.n_column-1)\n",
    "        last_state = init_state[:]\n",
    "        state = next_state[:]\n",
    "        last_action = action\n",
    "        if printFlag == True:\n",
    "            print state\n",
    "        while state != self.goal_point:\n",
    "            q_avilable_value = self.q_value[state[0], state[1], :]\n",
    "            if q_avilable_value.argmax() == q_avilable_value.argmin():\n",
    "                action = int(np.random.randint(low=0, high=8))\n",
    "            else:\n",
    "                action = int(ep_greedy(ep=self.ep, action_value=q_avilable_value, n_action = 8))\n",
    "            actionstr = str(action)\n",
    "            change = self.action[actionstr]\n",
    "            next_state_temp = [state[0] + change[0] + is_in_spc_area(self.spc_area, state), state[1] + change[1]]\n",
    "            next_state[0] = max(next_state_temp[0], 0)\n",
    "            next_state[0] = min(next_state[0], self.n_row-1)\n",
    "            next_state[1] = max(next_state_temp[1], 0)\n",
    "            next_state[1] = min(next_state[1], self.n_column-1)\n",
    "            reward = -1\n",
    "            q_value_change = self.alpha * (reward + self.gamma * self.q_value[state[0], state[1], action] - self.q_value[last_state[0], last_state[1], last_action])\n",
    "            self.q_value[last_state[0], last_state[1], last_action] = self.q_value[last_state[0], last_state[1], last_action] + q_value_change\n",
    "            last_state = state[:]\n",
    "            state = next_state[:]\n",
    "            last_action = action\n",
    "            if printFlag == True:\n",
    "                print state\n",
    "\n",
    "        \n",
    "windy_grid = windy_grid_world(10, 10, [0, 9, 4, 7], [5, 0], [5, 9])\n",
    "for i in tnrange(4000):\n",
    "    windy_grid.one_episode()\n",
    "for j in tnrange(10):\n",
    "    print 'testing one episode:'\n",
    "    windy_grid.one_episode(printFlag=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
